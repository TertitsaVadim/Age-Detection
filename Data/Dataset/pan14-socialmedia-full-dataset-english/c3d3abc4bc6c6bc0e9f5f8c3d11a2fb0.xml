<author type="socialmedia" lang="en" gender="xx" age_group="xx" url="">
	<documents count="12">
		<document id="8e77c21c8afb98e427cd0e3c8aac06be" url=""><![CDATA[Defining DHCP Lease Periods<br/><br/>To modify the default DHCP lease time for a pool of IP addresses, use the lease configuration command:<br /><br />Router1#configure terminal <br />Enter configuration commands, one per line.  End with CNTL/Z.<br />Router1(config)#ip dhcp pool 172.25.2.0/24<br />Router1(dhcp-config)#lease 2 12 30 <br />Router1(dhcp-config)#exit<br />Router1(config)#end<br />Router1#<br /><br />The lease command takes up to three options: lease days [hours] [minutes], with hours and minutes being optional. You can specify a maximum period of 365 days, 23 hours and 59 minutes, and a minimum of 1 second. The default is one day.<br /><br />The shorter the lease period, the faster you can reconfigure DHCP options that may need to change. Short lease periods also permit IP addresses to be returned to the address pool for reallocation more quickly. This can be useful in environments where a large number of end devices connect and disconnect frequently, as in public wireless networks, such as at an airport. A short lease period of say 30 minutes might be useful to ensure that IP addresses are returned quickly to the shared pool. However, short lease periods also mean that workstations must renew their leases more often, which puts an extra strain on the network and DHCP server.<br /><br />Conversely, a small office with a stable workforce may choose to increase their lease periods. Long lease periods can also reduce the impact of DHCP server failures. Unless a workstation reboots or needs to disconnect and reconnect to the network, most clients will wait until the lease is half expired before needing to talk to the server to renew it. If the server is unavailable, the client device will periodically retry the lease renewal until it succeeds. But most organizations have redundant DHCP servers, so there are few real benefits to extremely long lease periods.<br /><br />In most situations, the default lease period of one day is sufficient. It allows the administrators to change global options in a timely fashion without putting an unnecessary burden on the network or server.<br /><br />You can also configure the router to assign addresses with infinite lease periods by using the infinite keyword:<br /><br />Router1#configure terminal <br />Enter configuration commands, one per line.  End with CNTL/Z.<br />Router1(config)#ip dhcp pool COOKBOOK<br />Router1(dhcp-config)#lease infinite <br />Router1(dhcp-config)#exit<br />Router1(config)#end<br />Router1#<br /><br />Assigning an infinite lease period removes one of the major advantages of using DHCP. It can be extremely useful to be able to use DHCP to make wholesale configuration changes, but this means that the end devices have to check in periodically to renew their leases. Providing an indefinite lease period largely circumvents this advantage, since it forces you to wait until the end device disconnects and reconnects to the network before you can give it new information. Use the infinite keyword with caution.<br /><br />You can view the lease expiration times of your active clients with the show ip dhcp binding command:<br /><br />Router1#show ip dhcp binding <br />IP address       Hardware address        Lease expiration        Type<br />172.25.1.33      0100.0103.85e9.87       Infinite                Manual<br />172.25.1.53      0100.0103.ea1b.ed       Apr 11 2006 08:58 PM    Automatic<br />172.25.1.57      0100.6047.6c41.a4       Apr 11 2006 09:17 PM    Automatic<br />Router1#<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie voice lab equipment</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtcm91dGluZy1hbmQtc3dpdGNoaW5n" target="_blank">ccie r&amp;s lab topology</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5zcXVpZG9vLmNvbS9jY2llLWJvb3QtY2FtcDI_" target="_blank">CCIE Bootcamp</a>
]]>
		</document>
		<document id="bbc51fff669388935401c69aa6f115b" url=""><![CDATA[Filtering Multiport Applications<br/><br/>We say traditionally because this is not quite how things work when your FTP client software is driven through a web browser.<br />The server then makes a new TCP connection to the high-numbered port on the client device that it previously learned about through the control session. The source port for this connection is the well known FTP data port number, 20. This is backwards from most TCP connections, by which the client device connects to the server using a well known destination port number. Here the server connects to the client by using a well known source port number.<br />The client and server exchange the file, and then disconnect this FTP data connection, leaving the FTP control connection on port 21 active. The server will actually use the FTP data connection to transfer any bulk data, including directory listings as well as files. This recipe shows how you can easily match both the control and data traffic streams using an ACL.<br />In this example, we will assume that the client device is connected to the router's FastEthernet0/0 interface, perhaps through other downstream routers. And, for the sake of the example, we will assume that this is the only data that we want to allow.<br />So the router will receive a TCP packet from client device as it initiates the FTP session with destination port 21. We match this connection with the following Extended IP ACL:<br />Router1(config)#access-list 152 permit tcp any any eq ftp<br /><br />Note that we have used the keyword ftp in this ACL to mean TCP port 21.<br />Then, when there is data to exchange, the server will make a connection back to the client device on port number 20. The ACL keyword for this port is ftp-data:<br />Router1(config)#access-list 152 permit tcp any any eq ftp-data established<br /><br />Now, it's important to note that the access group is applied inbound to packets received on the client Fast Ethernet port. So this ACL will not apply to any of the packets sent from the server to the client device, but only those sent from the client to the server. However, this is sufficient because the devices cannot establish a TCP session unless they can both send packets.<br />For a more generic multi-port TCP application, you can specify a range of ports in the ACL with the range keyword, as follows:<br />Router1(config)#access-list 153 permit tcp any any range 6000 6063<br /><br />This example matches any packets whose destination port is between 6000 and 6063, inclusive, which is the range commonly used by the X Window system. For example, to match any TCP port number greater than 1023, you can use the gt keyword:<br />Router1(config)#access-list 153 permit tcp any any gt 1023 <br /><br />And there are, similarly, &quot;less than&quot; and &quot;not equal to&quot; operators for port numbers:<br />Router1(config)#access-list 153 permit tcp any any lt 1024 <br />Router1(config)#access-list 153 permit tcp any any neq 666<br /><br />As an aside, TCP port number 666 is used by the Doom interactive network game, making it an excellent candidate for filtering.<br />These same operations also apply identically for UDP port numbers:<br />Router1(config)#access-list 154 permit udp any any range 6000 6063<br />Router1(config)#access-list 155 deny udp any any gt 1023<br />Router1(config)#access-list 156 permit udp any any lt 1024 <br />Router1(config)#access-list 157 permit udp any any neq 666<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie security home lab</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5zcXVpZG9vLmNvbS9jY2llLXNpbXVsYXRvcg__" target="_blank">CCIE Simulator</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtcm91dGluZy1hbmQtc3dpdGNoaW5n" target="_blank">ccie r&amp;s blueprint v4.0</a>
]]>
		</document>
		<document id="d3d72d2c3b493789106d5a61bd4cf9a2" url=""><![CDATA[Frame Relay's Current Role<br/><br/>Today's fast and powerful computer processors run bandwidth-hungry applications that communicate, process, and transfer huge quantities of information, which include data, voice, and video. The older protocols are slow and do not scale well to suit this new trend of traffic. Frame Relay was developed to solve this problem.<br /><br />Before Frame Relay, companies used mainly expensive leased circuits to connect their remote offices. In the past, if a company wished to connect two remote offices to its central site and provide connectivity between all three sites, it would need to order and install three physical leased-line circuits from its provider. A fully meshed network between all three sites would have to be built, and each location had to maintain two separate physical leased-line connections to its remote sites. When using traditional leased-line circuits in an organization with nnumber of sites, the number of physical point-to-point connections required for a fully meshed network is in the order of n(n1)/2. Figure 1-8 considers an example of this scenario.<br /><br />Figure 1-8. A Fully Meshed Network with Leased-Line Circuits<br /><br />In the small organization in Figure 1-8, the end users at Remote Site A need to access the file server located at Remote Site B daily, but only during a certain period of the day. During the busiest time of the day, the average size of the files transferred to and from the file server at Site B is only between 512 KB and 1 MB. At that time, the traffic between the central office and the users at remote sites consists mostly of e-mail and frequent database access and queries. In this scenario, the bandwidth of the dedicated connections between all three sites is mostly unused during part of the day, or the lines are underutilized. A Frame Relay solution is more suited for this topological requirement, the type of traffic, and the traffic pattern.<br /><br />Figure 1-9 illustrates the alternative solution using Frame Relay with a star topology. All three sites are now connected to a shared Frame Relay network. Instead of building dedicated and expensive physical leased-line circuits, the organization can lease logical PVCs from the Frame Relay provider to connect all three locations. Using Frame Relay, each location has to maintain only a Frame Relay access device and a single physical access line connected to the Frame Relay network (the single physical access line can be a T1 or an E1 circuit). Logical PVCs are provisioned between all three sites, and each site has a direct logical connection to every other location. Furthermore, depending on each location's traffic usage, the minimum required bandwidth for each logical PVC can be subscribed. The CIR can be increased later in small increments if business needs arise.<br /><br />Figure 1-9. A Scalable Solution Using Frame Relay<br /><br />In another example, a company with 10 remote sites would require a total of 45 physical leased-line connections to provide a fully meshed network. It is a worldwide association of Frame Relay vendors, carriers, manufacturers, and users.<br /><br />NOTE<br /><br />In April 2003, the Frame Relay Forum has merged with the MPLS Forum to become the MPLS and Frame Relay Alliance ( <a href="http://en.pan.netcom/go/out/url=http%3A%2F%2Fwww.mplsforum.org"target="_blank" rel="nofollow">http://www.mplsforum.org</a>).<br /><br />Frame Relay Implementation Agreements are formally approved standards on how Frame Relay should be implemented to ensure operability and maximum cooperation between the manufacturers and vendors.<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5zcXVpZG9vLmNvbS9jY2llLWJvb3QtY2FtcA__" target="_blank">CCIE</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtcm91dGluZy1hbmQtc3dpdGNoaW5n" target="_blank">ccie r&amp;s dumps</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie voice lab study guide</a>
]]>
		</document>
		<document id="b7bc5444076f519464644f857999b587" url=""><![CDATA[The top three reasons to choose Cathay School for all your C<br/><br/>When a queue is full, IOS has no place to put newly arriving packets, so it discards them. This phenomenon is called tail drop. Oftentimes, when a queue fills, several packets are tail dropped at a time, given the bursty nature of data packets.<br /><br />Tail drop can have an overall negative effect on network traffic, particularly TCP traffic. When packets are lost, for whatever reason, TCP senders slow down their rate of sending data. When tail drops occur and multiple packets are lost, the TCP connections slow down even more. Also, most networks send a much higher percentage of TCP traffic than UDP, meaning that the overall network load tends to drop after multiple packets are tail dropped.<br /><br />Interestingly, overall throughput can be improved by discarding a few packets as a queue begins to fill, rather than waiting for the larger impact of tail drops. Cisco created Weighted Random Early Detection (WRED) specifically for the purpose of monitoring queue length and discarding apercentage of the packets in the queue to improve overall network performance. As a queue gets longer and longer, WRED begins to discard more packets, hoping that a small reduction in offered load that follows may be just enough to prevent the queue from filling.<br /><br />WRED uses several numeric settings when making its decisions. First, WRED uses the measured average queue depth when deciding if a queue has filled enough to begin discarding packets.<br /><br />WRED then compares the average depth to a minimum and maximum queue threshold, performing different discard actions depending on the outcome. Table 15-9 lists the actions.<br /><br />When the average queue depth is very low or very high, the actions are somewhat obvious, although the term full drop in Table 15-9 may be a bit of a surprise. When the average depth rises above the maximum threshold, WRED discards all new packets. Although this action might seem like tail drop, technically it is not, because the actual queue might not be full. So, to make this fine distinction, WRED calls this action category full drop.<br /><br />Table 15-9 WRED Discard Categories<br /><br />When the average queue depth is between the two thresholds, WRED discards a percentage of packets.<br /><br />The percentage grows linearly as the average queue depth grows from the minimum threshold to the maximum, as depicted in Figure 15-9 (which shows WRED’s default settings for IPP 0 traffic).<br /><br />Figure 15-9 WRED Discard Logic with Defaults for IPP 0<br />The last of the WRED numeric settings that affect its logic is the mark probability denominator(MPD), from which the maximum percentage of 10 percent is derived in Figure 15-9. IOS calculates the discard percentage used at the maximum threshold based on the simple formula 1/MPD.In the figure, an MPD of 10 yields a calculated value of, meaning the discard rate grows from 0 percent to 10 percent as the average queue depth grows from the minimum threshold to the maximum. Also, when WRED discards packets, it randomly chooses the packets to discard.<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tLw__" target="_blank">CCIE Bootcamp</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtc2VydmljZS1wcm92aWRlcg__" target="_blank">cisco ccie sp</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie voice real labs</a>
]]>
		</document>
		<document id="77c9966162cb9dca3a4ad3fa51a270ec" url=""><![CDATA[SVI Port Configuration<br/><br/>On a multilayer switch, you also can enable Layer 3 functionality for an entire VLAN on the switch. This allows a network address to be assigned to a logical interface—that of the VLAN itself. This is useful when the switch has many ports assigned to a common VLAN, and routing is needed in and out of that VLAN.<br /><br />In Figure 11-2, you can see how an IP address is applied to the switched virtual interface called VLAN 10. Notice that the SVI itself has no physical connection to the outside world; to reach the outside, VLAN 10 must extend through a Layer 2 port or trunk to the outside.<br /><br />The logical Layer 3 interface is known as an SVI. However, when it is configured, it uses the much more intuitive interface name vlan vlan-id, as if the VLAN itself is a physical interface.<br /><br />First, define or identify the VLAN interface; then assign any Layer 3 functionality to it with the following configuration commands:<br /><br />Switch(config)# interface vlan vlan-id<br />Switch(config-if)# ip address ip-address mask [secondary]<br /><br />The VLAN must be defined and active on the switch before the SVI can be used. Make sure that the new VLAN interface also is enabled with the no shutdown interface configuration command.<br /><br />Note: The VLAN and the SVI are configured separately, even though they interoperate. Creating or configuring the SVI doesn’t create or configure the VLAN; you still must define each one independently. <br />As an example, the following commands show how VLAN 100 is created and then defined as a Layer 3 SVI:<br />Switch(config)# vlan 100<br />Switch(config-vlan)# name Example_VLAN<br />Switch(config-vlan)# exit<br />Switch(config)# interface vlan 100<br />Switch(config-if)# ip address 192.168.100.1 255.255.255.0<br />Switch(config-if)# no shutdown<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie voice lab setup</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtcm91dGluZy1hbmQtc3dpdGNoaW5n" target="_blank">ccie r&amp;s training</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtc2VydmljZS1wcm92aWRlcg__" target="_blank">ccie sp bootcamp</a>
]]>
		</document>
		<document id="d7992b625f02532d604408b346858c19" url=""><![CDATA[TCAM Troubleshootingg<br/><br/>As previously mentioned, the two primary components of forwarding hardware are forwarding logic and backplane. A switch’s backplane, however, is rarely the cause of a switch performance issue, because most Cisco Catalyst switches have high-capacity backplanes. However, it is conceivable that in a modular switch chassis, the backplane will not have the throughput to support a fully populated modular chassis, where each card in the chassis supports the highest combination of port densities and port speeds. <br />The architecture of some switches allows groups of switch ports to be handled by separated hardware. Therefore, you might experience a performance gain by simply moving a cable from one switch port to another. However, to strategically take advantage of this design characteristic, you must be very familiar with the architecture of the switch with which you are working.<br /><br />A multilayer switch’s forwarding logic can impact switch performance. Recall that a switch’s forwarding logic is compiled into a special type of memory called ternary content addressable memory (TCAM), as illustrated in Figure 5-10. TCAM works with a switch’s CEF feature to provide extremely fast forwarding decisions. However, if a switch’s TCAM is unable, for whatever reason, to forward traffic, that traffic is forwarded by the switch’s CPU, which has a limited forwarding capability.<br /><br />The process of the TCAM sending packets to a switch’s CPU is called punting. Consider a few reasons why a packet might be punted from a TCAM to its CPU:<br /><br />? Routing protocols, in addition to other control plane protocols such as STP, that send multicast or broadcast traffic will have that traffic sent to the CPU.<br />? Someone connecting to a switch administratively (for example, establishing a Telnet session with the switch) will have their packets sent to the CPU.<br />? Packets using a feature not supported in hardware (for example, packets traveling over a GRE tunnel) are sent to the CPU.<br />? If a switch’s TCAM has reached capacity, additional packets will be punted to the CPU. A TCAM might reach capacity if it has too many installed routes or configured access control lists.<br /><br />From the events listed, the event most likely to cause a switch performance issue is a TCAM filling to capacity. Therefore, when troubleshooting switch performance, you might want to investigate the state of the switch’s TCAM. Please be sure to check documentation for your switch model, because TCAM verification commands can vary between platforms.<br /><br />As an example, the Cisco Catalyst 3550 Series switch supports a collection of show tcam commands, whereas Cisco Catalyst 3560 and 3750 Series switches support a series of show platform tcam commands. Consider the output from the show tcam inacl 1 statistics command issued on a Cisco Catalyst 3550 switch, as shown in Example 5-18. The number 1 indicates TCAM number one, because the Cisco Catalyst 3550 has three TCAMs. The inacl refers to access control lists applied in the ingress direction. Notice that fourteen masks are allocated, while 402 are available. Similarly, seventeen entries are currently allocated, and 3311 are available. For example, if your switch ports were configured as routing ports, you could reduce the amount of TCAM space used for storing MAC addresses, and instead use that TCAM space for Layer 3 processes.<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie security lab</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtc2VydmljZS1wcm92aWRlcg__" target="_blank">ccie sp books</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtcm91dGluZy1hbmQtc3dpdGNoaW5n" target="_blank">ccie r&amp;s lab equipment list</a>
]]>
		</document>
		<document id="c1ef6d2f9d0f7879038a4ce5080f3d24" url=""><![CDATA[Backdoor Routes<br/><br/>Having a low default AD (20) for eBGP routes can cause a problem in some topologies. Figure 12-6 shows a typical case, in which Enterprise 1 uses its eBGP route to reach network 99.0.0.0 in Enterprise 2. However, the two enterprises want to use the OSPF-learned route via the leased line between the two companies.<br /><br />Figure 12-6 The Need for BGP Backdoor Routes<br /><br />R1 uses its eBGP route to reach 99.0.0.0 because eBGP has a lower AD (20) than OSPF (110). One solution would be to configure the distance command to lower the AD of the OSPF-learned route. However, BGP offers an elegant solution to this particular problem through the use of the network backdoor command. In this case, if R1 configures the network 99.0.0.0 backdoor router BGP subcommand, the following would occur:<br /><br />? R1 would use the local AD (default 200) for the eBGP-learned route to network 99.0.0.0. <br /><br />? R1 does not advertise 99.0.0.0 with BGP. Given that logic, R1 can use a network backdoor command for each prefix for which R1 needs to use the private link to reach Enterprise 2. If the OSPF route to each prefix is up and working, R1 uses the OSPF (AD 110) route over the eBGP-learned (AD 200) route through the Internet. If the OSPF route is lost, the two companies can still communicate through the Internet.<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie security practice labs</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtcm91dGluZy1hbmQtc3dpdGNoaW5n" target="_blank">ccie routing and switching workbook</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtc2VydmljZS1wcm92aWRlcg__" target="_blank">ccie sp lab</a>
]]>
		</document>
		<document id="d98f7f3057a1c7b337bbae748353e49a" url=""><![CDATA[Wireless Domain Services<br/><br/>Wireless Domain Services (WDS) is a set of Cisco IOS Software features that enhances and simplifies wireless LAN client mobility, security, deployment, and management. WDS offers the following primary services for SWAN:<br /><br />? Fast Secure Roaming (FSR)—For time-sensitive applications, enables a wireless client to securely roam between access points in the same subnet or between subnets, enhances channel scanning, and provides fast IEEE 802.1X rekeying. Access point handoff times are within 50 ms, which is crucial for effective VoIP applications while users are roaming about the facility.<br /><br />? Radio management aggregation—Reduces the bandwidth necessary for radio management information, such as access point status messages, that is sent across the network, by eliminating redundant management information. Radio management information is sent to the CiscoWorks WLSE and provides the basis for monitoring functions, such as rogue access point detection and location.<br /><br />? Client tracking—Records client authentication and roaming events, which are sent to the CiscoWorks WLSE to monitor client associations to specific access points.<br /><br />Figure 23-1 illustrates how the FSR feature of WDS works:<br /><br />1.    AP1 must initially 802.1x authenticate with the WDS device to establish a secure connection.<br />2.    <br />The initial client authentication goes to a central AAA server to authenticate the user and authorize specific services. This occurs in approximately 500 ms. 2. When the client roams, the client informs WDS that roaming is taking place, and WDS sends the applicable key to the new access point (AP2 in this example). The handoff time between the access points is approximately 50 ms.<br /><br />Figure 23-1 Cisco SWAN Fast Secure Roaming<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie security rack</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtc2VydmljZS1wcm92aWRlcg__" target="_blank">ccie sp workbook</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tLw__" target="_blank">ccie rs training</a>
]]>
		</document>
		<document id="4e3dda54e4118bd98244e5bec28cf812" url=""><![CDATA[VPN Types Based on OSI Model Layer<br/><br/>VPNs can also be classified based on the OSI model layer at which they are constructed. This is an important distinction to make. For example, in the case of encrypted VPNs, the layer at which encryption occurs can determine how much traffic gets encrypted, as well as the level of transparency for the VPN's end users.<br /><br />Based on the OSI model layers, VPNs can be divided into the following three main categories:<br /><br />Data link layer VPNs<br />Network layer VPNs<br />Application layer VPNs<br />Data Link Layer VPNs<br /><br />With data link layer VPNs, two private networks are connected on Layer 2 of the OSI model using a protocol such as Frame Relay or ATM. Although these mechanisms provide a suitable way of creating VPNs, they are often expensive, because they require dedicated Layer 2 pathways to be created. Frame Relay and ATM protocols inherently do not provide encryption mechanisms. They only allow traffic to be segregated based on which Layer 2 connection it belongs to. Therefore, if you need further security, it is important to have some sort of encryption mechanism in place.<br /><br />Network Layer VPNs<br /><br />Network layer VPNs are created using Layer 3 tunneling and/or encryption techniques. An example is the use of the IPsec tunneling and encryption protocol to create VPNs. Other examples are GRE and L2TP protocols. It is interesting to note that although L2TP tunnels Layer 2 traffic, it uses Layer 3, the IP layer, to do this. Therefore, it is classified as a network layer VPN.<br /><br />The following chapters focus on network layer VPNs. Network layers provide a very suitable place to do encryption. The network layer is low enough in the stack to provide seamless connectivity to all applications running on top of it and is high enough to allow suitable granularity for the traffic that needs to be part of the VPN based on the extensive IP Addressing architecture in place. Due to its natural positioning in the IP market, Cisco focuses on network layer encryption as the main mechanism for creating VPNs.<br /><br />Application Layer VPNs<br /><br />Application layer VPNs are created to work specifically with certain applications. One very good example of such VPNs are SSL-based VPNs. SSL provides encryption between Web browsers and servers running SSL. Another good example is SSH. SSH is pushed as a mechanism for encrypted and secure login sessions to various network devices. SSH can encrypt and thus create VPNs for other application layer protocols, such as FTP and HTTP.<br /><br />One of the main drawbacks of application layer VPNs is that often they are not seamless. The user must perform an action to enable the end devices for creating the VPN for each of the various applications. As new services and corresponding applications are added, support for them must be developed as well. This is unlike network layer and link layer VPNs, which provide seamless VPN connectivity for all applications after the basic VPN has been set up.<br /><br />Figure 10-1 shows VPNs at the various OSI model layers.<br /><br />Figure 10-1. The Three Main Types of VPNs Based on the OSI Model Layers<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie voice written book</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tLw__" target="_blank">ccie training courses</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5zcXVpZG9vLmNvbS9jY2llLWJvb2stcGRm" target="_blank">CCIE</a>
]]>
		</document>
		<document id="b5ffa64f90d49e4790b9e6a9f71cd127" url=""><![CDATA[Different Types of Adjacencies<br/><br/>There are several types of adjacencies:  <br />Null adjacency   <br /><br />Packets destined for null-interface are dropped. This is used for dropping packets to unknown destinations. It can be used as an effective form of access filtering.   <br /><br />Glean adjacency   <br /><br />When a router is connected to a subnet, the FIB table maintains a prefix for the subnet rather than for each individual host. This subnet prefix points to a glean adjacency. When a packet must be forwarded to a specific host, the adjacency database is gleaned for the specific prefix.   <br /><br />Output of show ip cef glean appears as follows:   <br /><br />Punt adjacency <br />Features that require special handling or are not yet supported with CEF are forwarded to the next switching layer for handling.   <br /><br />Drop adjacency   <br /><br />Packets are dropped, but the prefix is checked. These two examples provide you an opportunity to see how the cache is populated by demand cache, which is used for fast switching, as well as how CEF populates the cache.    <br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtcm91dGluZy1hbmQtc3dpdGNoaW5n" target="_blank">ccie r&amp;s</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tLw__" target="_blank">ccie online training</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5zcXVpZG9vLmNvbS9jY2llLXZvaWNl" target="_blank">CCIE Voice</a>
]]>
		</document>
		<document id="7a6293478d1e1629ee8ea70634ff8e67" url=""><![CDATA[Setting Maximum Paths<br/><br/>The maximum number of routes over which IGRP can load balance is set with the maximum-paths paths command. Paths may be any number from one to six in IOS 11.0 and later and any number from one to four in earlier versions. The default for all versions is four. Figure 6.16 shows three parallel paths of varying costs from McCloy to network 172.18.0.0. The network administrator wants to load balance over a maximum of only two of these routes while ensuring that if either of these paths should fail, the third route will replace it. Figure 6.16. The maximum-paths and variance commands can be used together to configure load balancing over only two of the three links between McCloy and Bohlen. If either link fails, the third will take its place.<br /><br />The metrics from McCloy are: Via S0: 9765 + (2000 + 100) = 11865 Via S1: 19531 + (2000 + 100) = 21631 Via S2: 78125 + (2000 + 100) = 80225 The metric of the S2 route is 6.76 times as large as the lowest-cost metric, so the variance is seven. McCloy's IGRP configuration is router igrp 10 variance 7 network 172.20.0.0 network 192.168.1.0 network 192.168.2.0 maximum-paths 2 The variance command ensures that any of the three routes to 172.18.0.0 is feasible; the maximumpathscommand limits the load-sharing group to only the two best routes. The results of this configuration can be seen in Figure 6.17. The first routing table shows that McCloy was load balancing over the two links with the lowest of the three metrics, S0 and S1. After a failure of the S1 link, the second routing table shows that the router is now load balancing over the S0 and S2 links. In each instance, the router will load balance inversely proportional to the metrics of the two paths. Figure 6.17. The routing table for McCloy, before and after the failure of one of three links, shows the results of using the variance and maximum-paths commands to configure load sharing to 172.18.0.0.<br /><br />0 Responses<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5zcXVpZG9vLmNvbS9jY2llLWNlcnRpZmljYXRpb25z" target="_blank">CCIE Certifications</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtdm9pY2U_" target="_blank">ccie voice lab questions</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tLw__" target="_blank">CCIE</a>
]]>
		</document>
		<document id="19a394c55b754fd52d3e582688bc890" url=""><![CDATA[Headend VPN Edge QoS Options for Site-to-Site V3PNs<br/><br/>IPSec V3PNs can be configured in various ways at the central sites. Some enterprises simply overlay V3PNs on top of their existing private WANs; others subscribe to service providers that offer classes of service within their clouds. Many enterprises deploy VPN headends behind WAN aggregation routers to distribute CPU loads, while some perform encryption and QoS on the same box. Each of these options presents considerations on how V3PN policies optimally are applied on WAN aggregation routers.<br /><br />For enterprises that have overlaid IPSec VPNs on top of their private WAN topologies, the V3PN policies should be applied to the leased lines or Frame Relay/ATM PVCs.<br /><br />For enterprises that are subscribing to service providers that offer PE-to-CE QoS classes (including enterprises that are deploying IPSec VPNs over MPLS VPNs), V3PN policies need to be applied on the CE-to-PE links (complete with any re-marking that the service provider requires to map into these service provider classes), &quot;MPLS VPN QoS Design.&quot;<br /><br />For enterprises that are subscribing to service providers that do not offer explicit QoS (beyond an SLA) within their cloud and are using VPN headends behind WAN aggregation routers, the V3PN service policies would be applied to the WAN aggregator's (CE-to-PE) physical links. This prioritizes packets (by applications) and relies on the service provider's SLA to ensure that the delivery largely reflects the priority of the packets as they are handed off to the service provider. Such a configuration would require only a single QoS policy for a WAN aggregator (albeit, on a high-speed interface), but at the same time, it would involve an increased dependence on the service provider's SLA to deliver the desired QoS service levels.<br /><br />When the VPN headend routers have adequate CPU cycles to perform QoS, another option exists: hierarchical MQC policies that shape and queue (within the shaped rate) and are applied on a per-tunnel basis. A sample of per-tunnel hierarchal QoS policies is shown in Example 16-6. As with previous shaping design recommendations, the shaper is configured to shape to 95 percent of the remote site's line rate.<br /><br />Note<br /><br />It is critical to keep an eye on CPU levels when IPSec VPN encryption and per-tunnel QoS policies are applied on the same router. CPU levels, in general, should not exceed 75 percent during normal operating conditions. Configuring hierarchical shaping and queuing policies on a per-tunnel (per-SA) basis to a large number of sites could be very CPU intensive, especially when such sites experience periods of sustained congestion.<br /><br />Example 16-6. Per-Tunnel Hierarchical Shaping and Queuing MQC Policy for VPN Headends/WAN Aggregators<br /> !<br /> policy-map SHAPING-T1-TUNNEL<br />   class class-default<br />    shape average 1460000 14600 0     ! Shaped to 95% of T1 line-rate<br />    service-policy V3PN-EDGE          ! Nested queuing policy<br /> !<br /> !<br /> interface Tunnel120<br />  description VPN Pipe to V3PN Site#120 (T1 Link)<br />  bandwidth 1536<br />  ip address 10.10.120.1 255.255.255.252<br />  ip mtu 1420<br />  service-policy output SHAPING-T1-TUNNEL     ! Policy applied to tunnel int<br />  qos pre-classify                            ! Performance recommandation<br />  tunnel source 192.168.1.1<br />  tunnel destination 192.168.2.2<br />  crypto map VPN<br /><br /><a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5zcXVpZG9vLmNvbS9jY2llLWNlcnRpZmljYXRpb25z" target="_blank">CCIE Certifications</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5jYXRoYXlzY2hvb2wuY29tL2NjaWUtcm91dGluZy1hbmQtc3dpdGNoaW5n" target="_blank">ccie r&amp;s blueprint v4.0</a>, <a href="http://en.pan.netcom/go/out/url=-aHR0cDovL3d3dy5zcXVpZG9vLmNvbS9jY2llLWJvb3QtY2FtcDI_" target="_blank">CCIE Bootcamp</a>
]]>
		</document>
	</documents>
</author>